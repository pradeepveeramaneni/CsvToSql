# CsvToSql
CSV-to-SQL Real-Time ETL Microservices Pipeline (Kafka + .NET 8 + MSSQL)

This project implements a real-time, fault-tolerant ETL pipeline using Apache Kafka, .NET 8 microservices, and SQL Server (MSSQL).
It ingests large CSV datasets, streams records into Kafka, performs validation + transformation, and loads clean data into the database â€” all with DLQ, retries, idempotency, and high throughput.

ðŸŒŸ Key Features
âœ… Microservices architecture
Service	Responsibility
Ingest.Api	Upload CSV, stream each row to Kafka
Transformer.Worker	Validate + transform CSV rows â†’ typed events
Loader.Worker	Persist clean rows into MSSQL using EF Core
Common	Shared contracts, Kafka wrapper, validation
âœ… Event-driven messaging

Kafka topics:

csv.raw.rows â†’ raw CSV events

csv.rows.transformed â†’ validated + enriched events

csv.rows.dlq â†’ invalid rows / processing failures

Idempotent producers

Manual offset commits â†’ prevents data loss

Backpressure support

Dead Letter Queue (DLQ) on schema/parse/validation failures

âœ… Enterprise-grade error handling

FluentValidation for schema validation

Try-catch + DLQ fallback

Structured logging (Serilog)

Graceful shutdown & cancellation tokens

Retries with Kafka producer config

âœ… Database Layer

SQL Server

Clean normalized schema

EF Core with DbContext & migrations

Idempotent inserts (no duplication)

ðŸš€ Architecture Diagram
[ CSV Upload API ]
       â†“
[ Ingest.Api ] â†’ parses CSV â†’ pushes to Kafka (csv.raw.rows)
       â†“
[ Transformer.Worker ] â†’ validate + map â†’ (csv.rows.transformed)
       â†“               â†³ invalid â†’ (csv.rows.dlq)
[ Loader.Worker ] â†’ writes to MSSQL
       â†“
[ SQL Server ]

ðŸ› ï¸ Tech Stack
Category	Technology
Language	C#, .NET 8
Messaging	Apache Kafka
Database	SQL Server (SSMS / Docker)
ORM	EF Core
Validation	FluentValidation
Logging	Serilog
Docs	Swagger/OpenAPI
Architecture	Microservices + Event-Driven
ðŸ“ Folder Structure
CsvToSql.sln
src/
  Common/
    Common.csproj
    Contracts/Contracts.cs
    Messaging/KafkaHelpers.cs
    Observability/Logging.cs
  Ingest.Api/
    Ingest.Api.csproj
    Program.cs
    appsettings.json
    Controllers/CsvController.cs
    Services/IngestService.cs
  Transformer.Worker/
    Transformer.Worker.csproj
    Program.cs
    appsettings.json
    Services/TransformerService.cs
    Validation/RawRowValidator.cs
  Loader.Sql/
    Loader.Sql.csproj
    SalesDbContext.cs
    Entities.cs
    Migrations/20240930_Initial.sql  (optional raw SQL bootstrap)
  Loader.Worker/
    Loader.Worker.csproj
    Program.cs
    appsettings.json
    Services/LoaderService.cs
README.md

Kafka topics used:

csv.raw.rows

csv.rows.transformed

csv.rows.dlq

2ï¸âƒ£ Start Kafka (local install)
3ï¸âƒ£ Create Kafka topics
kafka-topics --bootstrap-server localhost:9092 --create --topic csv.raw.rows
kafka-topics --bootstrap-server localhost:9092 --create --topic csv.rows.transformed
kafka-topics --bootstrap-server localhost:9092 --create --topic csv.rows.dlq

4ï¸âƒ£ Run services
dotnet run --project src/Ingest.Api
dotnet run --project src/Transformer.Worker
dotnet run --project src/Loader.Worker

5ï¸âƒ£ Upload CSV
curl -F "file=@sales.csv" http://localhost:5117/swagger/index.html => http://localhost:5117/api/ingest/upload

âœ… Use Cases

High-volume ETL pipelines

CSV â†’ Kafka â†’ Database ingestion

Real-time data engineering

Distributed microservices architecture

Fault-tolerant data processing with DLQ
